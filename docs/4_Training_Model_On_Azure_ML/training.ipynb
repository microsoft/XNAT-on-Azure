{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Scenario 3: Training a model\n",
        "\n",
        "In this notebook, we train a machine learning model on remote AzureML compute resources. We'll be using the Padchest(insert link)\n",
        "dataset and upload 1000 images in an XNAT project called `Padchest1000`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## XNAT Setup\n",
        "We have a project named PadChest 1000 where we've uploaded scans and label data for each scan. We then mounted this project as an AzureML dataset. For each scan in the project we assume there's a corresponding `LABEL` directory with a `label.json` file as shown in Scenario 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Import packages\n",
        "Import Python packages you need in this session. Also display the Azure Machine Learning SDK version.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Import Azure Machine Learning SDKimport azureml\n",
        "import azureml\n",
        "from azureml.core import Workspace, Experiment, Environment, ScriptRunConfig\n",
        "from azureml.core.compute import ComputeTarget\n",
        "from azureml.widgets import RunDetails\n",
        "from azureml.core.dataset import Dataset\n",
        "from azureml.core.resource_configuration import ResourceConfiguration\n",
        "from azureml.core.conda_dependencies import CondaDependencies \n",
        "\n",
        "# check core SDK version number\n",
        "print(\"Azure ML SDK Version: \", azureml.core.VERSION)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Connect to workspace\n",
        "Create a workspace object from the existing workspace. `Workspace.from_config()` reads the file config.json and loads details into an object named `ws`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Load workspace from config file\n",
        "# The workspace is the top-level resource for Azure Machine Learning, \n",
        "# providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning.\n",
        "# Documentation: https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace\n",
        "ws = Workspace.from_config(path='./')\n",
        "print(\"Workspace:\",ws.name)\n",
        "\n",
        "# Create environment\n",
        "# An Environment defines Python packages, environment variables, and Docker settings that are used in machine learning experiments,\n",
        "# including in data preparation, training, and deployment to a web service.\n",
        "# Documentation: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.environment.environment?view=azure-ml-py\n",
        "env = Environment(name='xnat_scenario_3')\n",
        "\n",
        "# Install required packages from 'environment.yml' file\n",
        "env.python.conda_dependencies = CondaDependencies(conda_dependencies_file_path=\"./environment.yaml\")\n",
        "# Register environment. This allows to track the environment's versions, and reuse them in future runs\n",
        "env.register(workspace = ws)    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Create an experiment\n",
        "Create an experiment to track the runs in your workspace. A workspace can have multiple experiemnts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "experiment = Experiment(workspace=ws, name='xnat-scenario3-padchest-demo')\n",
        "print(\"Experiment:\",experiment.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Create or attach an existing compute resource\n",
        "Azure machine learning compute is a managed service that allows data scientists to train machine learning models on clusters of Azure virtual machines,\n",
        "including VMs with GPU support.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Connect to compute cluster\n",
        "# The compute cluster is a resource that can be shared with other users in your workspace\n",
        "# The compute scales up automatically when a job is submitted and shuts down when is no used\n",
        "# Documentation: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.computetarget?view=azure-ml-py#constructor\n",
        "compute_target_name = 'xnat-gpu-cluster'\n",
        "compute_target = ComputeTarget(workspace=ws, name=compute_target_name)\n",
        "print(\"Compute Target:\",compute_target.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Reference XNAT project as an AzureML Dataset\n",
        "Here we reference the `padchest` project created in XNAT as a an AzureML Dataset. \n",
        "We use XNAT's internal directory structure to mount \n",
        "only the files pertaining to this project. \n",
        "\n",
        "Note: Data-scientists should not be allowed to create or view other datasets in this workspace."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# A dataset is a named view of data that simply points or references the data you want to use as inputs\n",
        "# Documentation: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.dataset.dataset?view=azure-ml-py\n",
        "padchest_ds = Dataset.get_by_name(ws, name='XNAT PadChest1000 Dataset')\n",
        "padchest_ds.as_named_input('padchest')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Configure the training job\n",
        "Create a `ScriptRunConfig` object to specify configuration details for the training job. This includes\n",
        "- The directory that contains your script. All files in this directory are uploaded to the cluster nodes for execution\n",
        "- The compute target\n",
        "- The training script name\n",
        "- An environment containing the libraries needed for the script\n",
        "- Any other arguments required for the training script\n",
        "\n",
        "Here we mount our dataset as a directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "project_dir = './scripts'\n",
        "args = [\n",
        "    '--dataset_dir', padchest_ds.as_download(),\n",
        "    '--num_epochs', 25, '--azure_ml', True, '--batch_size_per_gpu', 64,\n",
        "    '--threads', 0\n",
        "]\n",
        "# ScriptRunConfig packages together the configuration information needed to submit a run in Azure ML,\n",
        "# including the script, compute target, environment, and any distributed job-specific configs\n",
        "# Once a script run is configured and submitted with the submit, a ScriptRun is returned\n",
        "# Documentation: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.scriptrunconfig?view=azure-ml-py\n",
        "config = ScriptRunConfig(\n",
        "    source_directory = project_dir, \n",
        "    script = 'main.py', \n",
        "    compute_target=compute_target,\n",
        "    environment = env,\n",
        "    arguments=args,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Submit the job to the cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "run = experiment.submit(config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Register the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "model = run.register_model(model_name='padchest1000_xnat_model',\n",
        "                           model_path='outputs/pc-densenet-densenet-best.pt',\n",
        "                           model_framework='PyTorch',\n",
        "                           model_framework_version='1.8.0',\n",
        "                           description=\"Padchest XRay Image Classifier (From XNAT project Padchest1000)\",\n",
        "                           tags={\"data\": \"XNAT PadChest1000 Dataset\", \"model\": \"classification\", \n",
        "                           \"class_names\": ['Pleural_Effusion', 'Consolidation', 'Atelectasis', 'Pleural_Abnormalities',\n",
        "                                           'Cardiomegaly', 'No_Finding', 'Pneumonia', 'Opacity'],\n",
        "                            \"number_classes\": \"8\" },\n",
        "                           resource_configuration=ResourceConfiguration(cpu=1, memory_in_gb=2))\n",
        "\n",
        "print(\"Model '{}' version {} registered \".format(model.name,model.version))"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3.7.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "0a54084e6b208ee8d1ce3989ffc20924477a5f55f5a43e22e699a6741623861e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
